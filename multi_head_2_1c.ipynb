{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-Head Regression model that predicts hours and minutes",
   "id": "d8871839d1adb19b"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np, tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D,\n",
    "                                     BatchNormalization, Dropout,\n",
    "                                     Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "c366d65038f8c505"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initializing the required parameters (Episodes, Mini-batching, Learning rate)",
   "id": "e000390669814925"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 150\n",
    "batch_size = 128\n",
    "learning_rate = 2e-5"
   ],
   "id": "4949df5ca7898d57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading and processing the data (Converting labels to total minutes, Normalizing pixel values)\n",
    "(We didn't use zipfile to load the data, so mmake sure the .npy files are present in the same directory as notebook)"
   ],
   "id": "178f611c0a5329bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Loading dataset ...\")\n",
    "\n",
    "images = np.load(\"images.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "images = images.astype(\"float32\")/255.0\n",
    "if images.ndim==3:\n",
    "    images = images[...,np.newaxis]\n",
    "\n",
    "# for Hours in range [0,12), minutes in [0,60)\n",
    "hours = (labels[:,0] % 12).astype(\"float32\")\n",
    "minutes = labels[:,1].astype(\"float32\")"
   ],
   "id": "f1088bd7c029e6db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train/Validation/Test Split of the data (80/10/10)",
   "id": "793df97f1e2f8a28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train,X_temp,yh_train,yh_temp,ym_train,ym_temp = train_test_split(\n",
    "    images,hours,minutes,test_size=0.2,random_state=42,shuffle=True)\n",
    "X_val,X_test,yh_val,yh_test,ym_val,ym_test = train_test_split(\n",
    "    X_temp,yh_temp,ym_temp,test_size=0.5,random_state=42,shuffle=True)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ],
   "id": "55cc6a1cafe46357",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A Custom Loss Function for circular hours, it handles circular regression, returns mean squared difference",
   "id": "1200985b071377ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def circular_mse_hours(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred) % 12.0\n",
    "    diff = tf.minimum(diff, 12.0 - diff)\n",
    "    return tf.reduce_mean(tf.square(diff))"
   ],
   "id": "444ab3ff642d1efb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Common Sense Error - Mean circular difference (minimizing around the clock).",
   "id": "22495ed6ec0920b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def common_sense_error(yh_t, yh_p, ym_t, ym_p):\n",
    "    true_total = (yh_t * 60 + ym_t) % 720\n",
    "    pred_total = (yh_p * 60 + ym_p) % 720\n",
    "    diff = np.abs(true_total - pred_total)\n",
    "    diff = np.minimum(diff, 720 - diff)\n",
    "    return np.mean(diff)"
   ],
   "id": "a3e3ec830ac97411"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizing the Total loss and Hour Loss (Circular MSE)",
   "id": "27eb38995676ffe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_a(h):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history[\"loss\"], label=\"Train Total Loss (Weighted)\")\n",
    "    plt.plot(h.history[\"val_loss\"], label=\"Val Total Loss (Weighted)\")\n",
    "    plt.title(\"Total Weighted Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history[\"hour_output_loss\"], label=\"Train Hour Loss (Circular MSE)\")\n",
    "    plt.plot(h.history[\"val_hour_output_loss\"], label=\"Val Hour Loss (Circular MSE)\")\n",
    "    plt.title(\"Hour Loss (Circular MSE)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "f383fd193faeedd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizing the Hour MAE and Minute MAE (Mean Absolute Error)",
   "id": "1be29564fb4a19cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_b(h):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history[\"hour_output_mae\"], label=\"Train Hour MAE (hours)\")\n",
    "    plt.plot(h.history[\"val_hour_output_mae\"], label=\"Val Hour MAE (hours)\")\n",
    "    plt.title(\"Hour MAE (Mean Absolute Error)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MAE (hours)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history[\"minute_output_mae\"], label=\"Train Minute MAE (minutes)\")\n",
    "    plt.plot(h.history[\"val_minute_output_mae\"], label=\"Val Minute MAE (minutes)\")\n",
    "    plt.title(\"Minute MAE (Mean Absolute Error)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MAE (minutes)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "78a145bca33c0078"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A multi-head regression CNN with hour and minute outputs with Adam optimizer and weighted multi-output losses",
   "id": "8657325fc5a86d9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_multihead(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = Conv2D(32,3,activation=\"relu\",padding=\"same\")(inp)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(64,3,activation=\"relu\",padding=\"same\")(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128,3,activation=\"relu\",padding=\"same\")(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256,3,activation=\"relu\",padding=\"same\")(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512,activation=\"relu\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    out_h = Dense(1,activation=\"linear\",name=\"hour_output\")(x)\n",
    "    out_m = Dense(1,activation=\"linear\",name=\"minute_output\")(x)\n",
    "\n",
    "    model = Model(inp,[out_h,out_m])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={\"hour_output\": circular_mse_hours, \"minute_output\": \"mse\"},\n",
    "        loss_weights={\"hour_output\": 2.0, \"minute_output\": 1.0},\n",
    "        metrics={\"hour_output\": \"mae\", \"minute_output\": \"mae\"})\n",
    "    return model"
   ],
   "id": "57d2eee157527f4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model with early stopping and reduce learning rate on plateau and Results in MAE and Common Sense Error.",
   "id": "4203d056e696e194"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = build_multihead(X_train.shape[1:])\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\",patience=15,restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,patience=6,min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, {\"hour_output\": yh_train, \"minute_output\": ym_train},\n",
    "    validation_data=(X_val, {\"hour_output\": yh_val, \"minute_output\": ym_val}),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "plot_training_a(history)\n",
    "plot_training_b(history)\n",
    "\n",
    "yh_pred, ym_pred = model.predict(X_test)\n",
    "yh_pred, ym_pred = yh_pred.flatten(), ym_pred.flatten()\n",
    "\n",
    "mae_h = np.mean(np.abs(yh_pred - yh_test))\n",
    "mae_m = np.mean(np.abs(ym_pred - ym_test))\n",
    "common_err = common_sense_error(yh_test,yh_pred,ym_test,ym_pred)\n",
    "\n",
    "print(\"\\nEvaluation\")\n",
    "print(f\"Hour MAE (hours):   {mae_h:.3f}\")\n",
    "print(f\"Minute MAE (minutes): {mae_m:.2f}\")\n",
    "print(f\"Common-sense MAE:   {common_err:.2f} minutes\")"
   ],
   "id": "18a69121ed6d48c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
