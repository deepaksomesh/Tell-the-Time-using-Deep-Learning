{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression model",
   "id": "9a5bfd8d2f41b43f"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D,\n",
    "                                     BatchNormalization, Dropout,\n",
    "                                     Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "d08b686a429b8b43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initializing the required parameters (Episodes, Mini-batching, Learning rate)",
   "id": "4c7408a27273afeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 5e-5"
   ],
   "id": "909e16af69767430"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading and processing the data (Checking the validity, Converting labels to total minutes, Normalizing pixel values)\n",
    "(We didn't use zipfile to load the data, so mmake sure the .npy files are present in the same directory as notebook)"
   ],
   "id": "d06df74e3416d84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Loading dataset ...\")\n",
    "images = np.load(\"images.npy\")\n",
    "labels = np.load(\"labels.npy\")   # shape (N, 2) â†’ [hour, minute]\n",
    "\n",
    "valid = (\n",
    "    (labels[:,0] >= 0) & (labels[:,0] < 24) &\n",
    "    (labels[:,1] >= 0) & (labels[:,1] < 60)\n",
    ")\n",
    "images, labels = images[valid], labels[valid]\n",
    "\n",
    "hours = labels[:,0] % 12\n",
    "minutes = labels[:,1]\n",
    "targets = hours + minutes/60.0\n",
    "targets = targets.astype(\"float32\")\n",
    "\n",
    "images = images.astype(\"float32\") / 255.0\n",
    "if images.ndim == 3:\n",
    "    images = images[..., np.newaxis]"
   ],
   "id": "9bc53befcbe0e486"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train/Validation/Test Split of the data (80/10/10)",
   "id": "9108d2a9414c3fde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, targets, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ],
   "id": "1862920946b03810"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Common Sense Error - Mean circular difference (minimizing around the clock).",
   "id": "526b62a6507f012"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def common_sense_error(y_true, y_pred):\n",
    "    diff = np.abs(y_true - y_pred) % 12.0\n",
    "    diff = np.minimum(diff, 12.0 - diff)\n",
    "    return np.mean(diff * 60.0)"
   ],
   "id": "53a71e7aaf2f3254"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizing the loss MSE and MAE metrics",
   "id": "e9f2f20964175efb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training(h):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h.history[\"loss\"], label=\"train\")\n",
    "    plt.plot(h.history[\"val_loss\"], label=\"val\")\n",
    "    plt.title(\"Loss (MSE)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history[\"mae\"], label=\"train\")\n",
    "    plt.plot(h.history[\"val_mae\"], label=\"val\")\n",
    "    plt.title(\"Mean Absolute Error\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MAE (hours)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "75a1d9e176e492d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A regression CNN architecture with Adam optimizer, MSE loss, and MAE metrics",
   "id": "fb5d0f2ee2e77df3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_regression_cnn(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(inp)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    out = Dense(1, activation=\"linear\", name=\"time_regression\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model"
   ],
   "id": "af90decc985679f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model with early stopping and reduce learning rate on plateau and Results in MAE and Common Sense Error.",
   "id": "a587215e650cabe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = build_regression_cnn(X_train.shape[1:])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "plot_training(history)\n",
    "\n",
    "preds = model.predict(X_test).reshape(-1)\n",
    "mae_hours = np.mean(np.abs(preds - y_test))\n",
    "common_err = common_sense_error(y_test, preds)\n",
    "\n",
    "print(f\"MAE (hours):  {mae_hours:.4f}\")\n",
    "print(f\"Common-sense MAE: {common_err:.2f} minutes\")"
   ],
   "id": "416d5c9bbb9e0d18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
